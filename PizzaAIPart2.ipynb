{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning Intro\n",
    "Let's build a common understanding of machine learning by coding up the same decision tree in the traditional way and in the machine learning way.\n",
    "\n",
    "---\n",
    "\n",
    "## Traditional rule based systems / Software 1.0\n",
    "The process is straightforward. The software engineer writes the rules based on which the system is making decisions. Then runs the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function returns True or False depending on whether variable a and b are smaller than 15 and 20 respectively.\n",
    "# Decision rules.\n",
    "def make_decision(a, b):\n",
    "    if (a < 15):\n",
    "        if (b < 20):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if (b < 20):\n",
    "            return False\n",
    "        else:\n",
    "            return True \n",
    "        \n",
    "#print output based on rules\n",
    "make_decision(10, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning systems / Software 2.0\n",
    "Software engineer writes a program that figures out the rules of decision making based on past examples of decisions. The process is more involved. Steps:\n",
    "1. Collection of past examples of decision (training data)\n",
    "2. Clean the data, transform it into the format your algorithm likes (binary classes, vectors, numbers)\n",
    "3. Train then test your algorithm and fine-tune it\n",
    "4. Run predictions on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import machine learning algorithm\n",
    "from sklearn import tree\n",
    "\n",
    "# Steps 1 and 2. Training data (past decision examples)\n",
    "train_x = [[10, 34], [9, 4], [45, 20], [14, 20], [15, 20], [14, 19], [15, 19], [22, 17]]\n",
    "train_y = [ False,    True,    True,     False,    True,     False,    False,    False]\n",
    "\n",
    "# Step 3. Train ML algo (make your computer figure out the decision rules behind the training data)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "#Step 4\n",
    "print(clf.predict([[2, 2], [16, 17], [15, 20], [1, 32]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "&nbsp; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c85876b-1b19-4c50-8330-a2c9dbd91f32",
    "_uuid": "3cae972238580fe9c4fb6a184b3661b232f77458"
   },
   "source": [
    "&nbsp; \n",
    "\n",
    "&nbsp; \n",
    "\n",
    "---\n",
    "### That's a very simple example, so let's take one more step forward.\n",
    "\n",
    "# Let's explore the process of machine learning through a fictional story!\n",
    "\n",
    "&nbsp; \n",
    "\n",
    "![title](picture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Arstotzka!\n",
    "### Things aren't going well and the country's food supplies are running short. \n",
    "### If citizens want to eat, they have to send a letter to the Department of Food Supplies. The officials judge their requests and either reject them or send a slice of pizza.\n",
    "\n",
    "### You're the department's software engineer and your boss told you automate request approval with this new thing called machine learning... Your boss gave you the past decisions in the file, data.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1 - Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_title</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>requester_received_pizza</th>\n",
       "      <th>requester_interests</th>\n",
       "      <th>account_age</th>\n",
       "      <th>requester_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_l25d7</td>\n",
       "      <td>Request Colorado Springs Help Us Please</td>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>792.420405</td>\n",
       "      <td>Nirsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_rcb83</td>\n",
       "      <td>[Request] California, No cash and I could use ...</td>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>False</td>\n",
       "      <td>['AskReddit', 'Eve', 'IAmA', 'MontereyBay', 'R...</td>\n",
       "      <td>1122.279838</td>\n",
       "      <td>Vescillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>t3_lpu5j</td>\n",
       "      <td>[Request] Hungry couple in Dundee, Scotland wo...</td>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>771.616181</td>\n",
       "      <td>Nirsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>t3_mxvj3</td>\n",
       "      <td>[Request] In Canada (Ontario), just got home f...</td>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>False</td>\n",
       "      <td>['AskReddit', 'DJs', 'IAmA', 'Random_Acts_Of_P...</td>\n",
       "      <td>741.035602</td>\n",
       "      <td>Vescillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>t3_1i6486</td>\n",
       "      <td>[Request] Old friend coming to visit. Would LO...</td>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>False</td>\n",
       "      <td>['BrosWeightLoss', 'RandomActsOfCookies', 'Ran...</td>\n",
       "      <td>308.633819</td>\n",
       "      <td>Nirsk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Unnamed: 0.1 request_id  \\\n",
       "0           0            0   t3_l25d7   \n",
       "1           1            1   t3_rcb83   \n",
       "2           2            2   t3_lpu5j   \n",
       "3           3            3   t3_mxvj3   \n",
       "4           4            4  t3_1i6486   \n",
       "\n",
       "                                       request_title  \\\n",
       "0            Request Colorado Springs Help Us Please   \n",
       "1  [Request] California, No cash and I could use ...   \n",
       "2  [Request] Hungry couple in Dundee, Scotland wo...   \n",
       "3  [Request] In Canada (Ontario), just got home f...   \n",
       "4  [Request] Old friend coming to visit. Would LO...   \n",
       "\n",
       "                             request_text_edit_aware requester_received_pizza  \\\n",
       "0  Hi I am in need of food for my 4 children we a...                    False   \n",
       "1  I spent the last money I had on gas today. Im ...                    False   \n",
       "2  My girlfriend decided it would be a good idea ...                    False   \n",
       "3  It's cold, I'n hungry, and to be completely ho...                    False   \n",
       "4  hey guys:\\n I love this sub. I think it's grea...                    False   \n",
       "\n",
       "                                 requester_interests  account_age  \\\n",
       "0                                                 []   792.420405   \n",
       "1  ['AskReddit', 'Eve', 'IAmA', 'MontereyBay', 'R...  1122.279838   \n",
       "2                                                 []   771.616181   \n",
       "3  ['AskReddit', 'DJs', 'IAmA', 'Random_Acts_Of_P...   741.035602   \n",
       "4  ['BrosWeightLoss', 'RandomActsOfCookies', 'Ran...   308.633819   \n",
       "\n",
       "  requester_city  \n",
       "0          Nirsk  \n",
       "1       Vescillo  \n",
       "2          Nirsk  \n",
       "3       Vescillo  \n",
       "4          Nirsk  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### As you can see, the first three columns are just duplicates, so let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The table is too big to see. Let's pretty print the 1018th row!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID:\n",
      " t3_1fhc8g \n",
      "\n",
      "Title:\n",
      " [Request] Broke student, been living off pasta for a good few weeks. A pizza may save my stomach's sanity! (UK) \n",
      "\n",
      "Text:\n",
      " As lovely as cheesy pasta is, it gets a bit boring after a while! I'm heading back to work over summer in a few weeks, so I can pay it forward when I get my first paycheck through :) \n",
      "\n",
      "Received:\n",
      " False \n",
      "\n",
      "Requester interests:\n",
      " [AdviceAnimals, Antihumor, AskReddit, CornyJoke, FanTheories, FestivalSluts, GifSound, Heavymind, Hipsterchicks, IAmA, InternetIsBeautiful, LucidDreaming, Minecraft, Music, Paranormal, ProjectReddit, Psychonaut, RedditDayOf, RepublicOfMusic, Shaboozey, ShittyFanTheories, Slender_Man, Southampton, SquaredCircle, StonerEngineering, Straightdan, Survive, UniversityofReddit, WTF, WWE, WeAreTheMusicMakers, Yogscast, askdrugs, askscience, circlebroke, circlejerk, civ, coestar, conspiracy, counting, creepy, cringe, dayz, dayzlfg, ephemera, explainlikeimfive, facepalm, fffffffuuuuuuuuuuuu, fifthworldproblems, footballmanagergames, freewarewin, fucklebrothers, funny, futurebeats, gaming, geek, glitch_art, gonewild, heresapictureofme, ifyoulikeblank, keto, killingfloor, listentothis, meat, metacirclejerk, mildlyinteresting, mturk, newreddits, newzealand, nocontext, nosleep, notcirclejerk, offbeat, oxford, pics, queensnostalgia, radiohead, reactiongifs, redheads, rightinthechildhood, seduction, see, shamelessplug, shittyaskscience, skyrim, sleuths, technology, terriblefacebookmemes, thesims, tipofmypenis, tipofmytongue, todayilearned, unitedkingdom, whatwouldyoudoif, youhadtobethere] \n",
      "\n",
      "Account age:\t 739.2040509259259 \n",
      "\n",
      "Requester city:\t Nirsk \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1017\n",
    "print('UID:\\n', df['request_id'][i], '\\n')\n",
    "print('Title:\\n', df['request_title'][i], '\\n')\n",
    "print('Text:\\n', df['request_text_edit_aware'][i], '\\n')\n",
    "print('Received:\\n', df['requester_received_pizza'][i], '\\n')\n",
    "print('Requester interests:\\n', df['requester_interests'][i].replace(\"'\", \"\"), '\\n')\n",
    "print('Account age:\\t', df['account_age'][i], '\\n')\n",
    "print('Requester city:\\t', df['requester_city'][i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's investigate how many people actually received pizzas in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        3045\n",
       "True                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          994\n",
       "['2007scape', '3DS', 'AdviceAnimals', 'AnimalCrossing', 'AskReddit', 'Bowling', 'Eve', 'Foreversend', 'FryeMadden', 'FryeMadden2', 'HIMYM', 'IAmA', 'KarmaCourt', 'KarmaCourtAttorneys', 'KarmaCourtJury', 'KerbalSpaceProgram', 'Madden', 'Music', 'NBA2K13', 'PS4', 'Random_Acts_Of_Pizza', 'WTF', 'WhatsInThisThing', 'aviation', 'aww', 'cpp', 'fffffffuuuuuuuuuuuu', 'flightattendants', 'flying', 'funny', 'gamedev', 'gaming', 'gif', 'golf', 'halo', 'learnprogramming', 'loseit', 'mcservers', 'offmychest', 'pics', 'rebelmadden', 'roosterteeth', 'todayilearned', 'usu', 'videos', 'windowsphone', 'xboxone']       1\n",
       "Name: requester_received_pizza, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"requester_received_pizza\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Ooops, there must be a mistake in the data, which reminds me that we should drop N/A values, and we should only work with rows that have True/False values in their \"requester_received_pizza\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3045\n",
       "True      994\n",
       "Name: requester_received_pizza, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(\"\")\n",
    "df = df[df[\"requester_received_pizza\"].isin(['True','False'])]\n",
    "\n",
    "#Let's try again\n",
    "df[\"requester_received_pizza\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24d5a591-79a6-4740-8b58-c76fef459355",
    "_uuid": "d231a3cdad2807893f44de861892093d02cb07a7"
   },
   "source": [
    "### Summary of fields:\n",
    "\n",
    "**Input data**:\n",
    " - `request_id`: unique identifier for the request \n",
    " - `request_title`: title of the reddit post for pizza request\n",
    " - `request_text_edit_aware`: expository to request for pizza\n",
    " - `requester_interests`: collected tags on what the interests of the requester are\n",
    " - `account_age`: how old is the account\n",
    " - `requester_city`: city requester is from\n",
    " \n",
    "**Output decision made**:\n",
    " - `requester_recieved_pizza`: whether requester gets his/her pizza\n",
    " \n",
    "For our purpose let's choose the request text, interests and city as features to predict whether a person should receive a pizza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2 - Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b869481f-c713-4aa6-aa0d-f2e5f4b2abfc",
    "_uuid": "a2cacb2270490a92ec9a7e920e8ca17c730c1e09"
   },
   "source": [
    "### Split training data before vectorization\n",
    "\n",
    "The first thing to do is to split our training data into 2 parts:\n",
    "\n",
    " - **training**: Use for training our model\n",
    " - **validation**: Use to check the \"soundness\" of our model, by running the prediction on the data and checking how many did our model get right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "_cell_guid": "0b61f317-079b-4253-b94a-a87b71bd47fb",
    "_uuid": "ac1e8766dcf5d7d81fe4fd3a95e7bc659fbf1978"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "train, valid = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8677912b-d9e2-4fd8-b722-acb3320af4fc",
    "_uuid": "f97576104bbabfc720fa0794ab6a8fc4e043f109"
   },
   "source": [
    "### Data formats and Countvectorizing\n",
    "Machine learning algorithms in most cases don't know what to do with characters and strings, so we'll need to transform our strings. One way to do so is countvectorization. But what is that? Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 4)\t3\n",
      "  (0, 1)\t2\n",
      "  (0, 2)\t2\n",
      "  (0, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "# create countvectorizer object\n",
    "count_vect_text = CountVectorizer()\n",
    "\n",
    "# the count vectorizer just counts the frequency of each unique word in the sequence.\n",
    "myString = [\"She sells sea shells. The shells she sells are surely sea shells.\"]\n",
    "\n",
    "# the output is in the format:   (<doc indx-ignore>, <indx in the string>)  <number of times it occurs>\n",
    "print(count_vect_text.fit_transform(myString))\n",
    "\n",
    "# therefore from the result we see that for instance:\n",
    "#  - the words at positions 5,0 and 6 in the string occur once referring to \"She\", \"sells\", \"surely\"\n",
    "#  - the one in the 4th position occurs 3 times referring to \"shells\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's countvectorize our whole training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "_cell_guid": "02efe9a8-00e4-41fa-9b6a-5fbebe751feb",
    "_uuid": "4549079bfedbbff679ccde5f083b3c6814e73233",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3231, 2230)\n",
      "(3231, 500)\n",
      "(3231, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "stopwords = [\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"    with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"]\n",
    "#\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\"\n",
    "    \n",
    "train_y = train['requester_received_pizza']\n",
    "valid_y = valid['requester_received_pizza']    \n",
    "\n",
    "count_vect_text = CountVectorizer(stop_words=stopwords, max_features=4000, min_df=6)\n",
    "train_x = coo_matrix(count_vect_text.fit_transform(train['request_text_edit_aware']))\n",
    "valid_x = coo_matrix(count_vect_text.transform(valid['request_text_edit_aware']))\n",
    "print(train_x.shape)\n",
    "\n",
    "count_vect_int = CountVectorizer(max_features=500, min_df=3)\n",
    "train_x_int = coo_matrix(count_vect_int.fit_transform(train['requester_interests']))\n",
    "valid_x_int = coo_matrix(count_vect_int.transform(valid['requester_interests']))\n",
    "print(train_x_int.shape)\n",
    "\n",
    "count_vect_city = CountVectorizer()\n",
    "train_x_city = coo_matrix(count_vect_city.fit_transform(train['requester_city']))\n",
    "valid_x_city = coo_matrix(count_vect_city.transform(valid['requester_city']))\n",
    "print(train_x_city.shape)\n",
    "\n",
    "train_x = hstack([train_x, train_x_int, train_x_city]).toarray()\n",
    "valid_x = hstack([valid_x, valid_x_int, valid_x_city]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d7ae411-ae2c-4098-beb2-ac6c2dc267a9",
    "_uuid": "3aaf138395ccdfe7a29d89d1b58da9db96ae8b36"
   },
   "source": [
    "---\n",
    "# Step 3 - Training model\n",
    "Finally, we arrived to the part everyone was waiting for! In this step, we'll just test a few different classifiers to see how they perform.\n",
    "\n",
    "### Let's try first a Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "_cell_guid": "8a159538-c58a-485d-bc23-d7115ee55a77",
    "_uuid": "44cee633360c7989a3d67716553ef4e2bc9eae87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB() \n",
    "clf.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c2776b5-6515-4321-a7e7-f925534241d6",
    "_uuid": "fbec702a6003287ea5d49049be532ee96b6d7a14"
   },
   "source": [
    "### Let's get a sense of how good our classifier is on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "_cell_guid": "a0bba339-cd62-46e9-9106-55ef15000dc5",
    "_uuid": "b5f7b1ac26a30b568d3f5dec2a3f76c34a316ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza giving accuracy:  0.7314356435643565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "predictions_valid = clf.predict(valid_x)\n",
    "print('Pizza giving accuracy: ', f1_score(predictions_valid, valid_y, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try another algorithm, Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza giving accuracy:  0.7277227722772277\n"
     ]
    }
   ],
   "source": [
    "#best params: alpha=0.01, loss='log', penalty='elasticnet', l1_ratio=0, tol=None, max_iter=30\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_SVM = SGDClassifier(max_iter=5, tol=None) \n",
    "clf_SVM.fit(train_x, train_y) \n",
    "predictions_valid = clf_SVM.predict(valid_x)\n",
    "print('Pizza giving accuracy: ', f1_score(predictions_valid, valid_y, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get better results with the SVM, but oftentimes it helps to tweak some parameters of the algorithm. I played around to find the best combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza giving accuracy:  0.7735148514851485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_SVM = SGDClassifier(alpha=0.01, loss='log', penalty='elasticnet', l1_ratio=0, tol=None, max_iter=30) \n",
    "clf_SVM.fit(train_x, train_y) \n",
    "predictions_valid = clf_SVM.predict(valid_x)\n",
    "print('Pizza giving accuracy: ', f1_score(predictions_valid, valid_y, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6013d400-4a01-438a-9afe-b540b6ec78b9",
    "_uuid": "dbf9eb2a3dde29a26ae51df05f120ee26334d0c3"
   },
   "source": [
    "---\n",
    "# Step 4 - Run predictions on new data\n",
    "Now we take the data that we have to make decisions on. This dataset has all the features and the algorithm will decide whether these people will get pizzas or not based on the rules it learnt from past decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "_cell_guid": "2fe3ff2b-5157-43b2-ad8d-55389ad28a0e",
    "_uuid": "450827a713f7eaaa2d3c3504b038a513c27b3b20",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_data.csv')\n",
    "test = test.fillna(\"\")\n",
    "test_x = coo_matrix(count_vect_text.transform(test['request_text_edit_aware']))\n",
    "test_x_int = coo_matrix(count_vect_int.transform(test['requester_interests']))\n",
    "test_x_city = coo_matrix(count_vect_city.transform(test['requester_city']))\n",
    "test_x = hstack([test_x, test_x_int, test_x_city]).toarray()\n",
    "\n",
    "predictions = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ef6b8e68-46be-4944-b809-872ddeabf386",
    "_uuid": "51a804beaf030dbb8cbdfc320d6a26d86991d274"
   },
   "source": [
    "**Note:** Since we don't have the `requester_received_pizza` field in test data, we can't measure accuracy. But we can do some exploration as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "_cell_guid": "80300555-265f-4557-8b52-17c343a34c58",
    "_uuid": "4ad28c27f351de96d40b68aed92217b17f71c542",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1312\n",
       "True      319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Very niiice!\n",
    "Out of the 1600 new requests, our algorithm rejected 1303 and approved 328, which is similar to the original manual decisions. \n",
    "\n",
    "**Now the government of Arstotzka can fire all its employees, and only employ this one algorithm! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4+1 - Assume something is wrong and find it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities of pizza receivers: \n",
      " Nirsk       253\n",
      "Vescillo     66\n",
      "Name: requester_city, dtype: int64\n",
      "\n",
      "Total requests from each city: \n",
      " Nirsk       843\n",
      "Vescillo    788\n",
      "Name: requester_city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's concat the predictions and features into one table, and select the rows that received a pizza\n",
    "pred_df = pd.concat([test, pd.Series(predictions)], axis=1)\n",
    "received_pizza = pred_df[pred_df[0] == 'True']\n",
    "\n",
    "# as a random guess let's look at where are the people with pizzas from?\n",
    "print(\"Cities of pizza receivers: \\n\",received_pizza['requester_city'].value_counts())\n",
    "\n",
    "# let's look at how many people are from those cities in general\n",
    "print(\"\\nTotal requests from each city: \\n\",pred_df['requester_city'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you see something wrong?\n",
    "\n",
    "Nirsk and Vescillo have roughly the same population, but for some reason Nirsk received 3.4 times more pizza!! We'll get back to this below.\n",
    "\n",
    "### This was a lot, right? Let's recap what we just did!\n",
    "1. short intro into Machine Learning\n",
    "- we moved onto a bigger project\n",
    "- loaded pizza data\n",
    "- split into training and test sets\n",
    "- vectorized text\n",
    "- tested different models (Naive bayes, SVM)\n",
    "- saw that there is a bias in the results towards one city\n",
    "\n",
    "It is crucial in machine learning to understand the biases in the training dataset, because the algorithms will only learn and reinforce those. \n",
    "\n",
    "[A real life example](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) is when people used an algorithm to decide whether a prison inmate should be pardonned. The problem was that the judges were racially biased towards white people and therefore the algorithm also learned that black people should stay in prison longer.\n",
    "\n",
    "In our fictional Arstotzka example, the people making the original decision might be from Nirsk and sympathized with those people more. However, this is not the behaviour we want our algorithm to have.\n",
    "\n",
    "The same kind of bias in real world datasets has serious consequences, when they are applied to university admissions, insurance, loans and criminal predictions. Engineers have the responsibility to find the biases and fix them. [These scientists managed to fix gender bias in the Google Word2Vec model](https://arxiv.org/pdf/1607.06520.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
