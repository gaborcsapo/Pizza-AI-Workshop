{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Intro\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "## Traditional rule based systems / Software 1.0\n",
    "The process is straightforward. The software engineer writes the rules based on which the system is making decisions. Then runs the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decision rules\n",
    "def make_decision(a, b):\n",
    "    if (a < 15):\n",
    "        if (b < 20):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if (b < 20):\n",
    "            return False\n",
    "        else:\n",
    "            return True \n",
    "        \n",
    "#print output based on rules\n",
    "make_decision(10, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning systems / Software 2.0\n",
    "Software engineer writes a program that figures out the rules of decision making based on past examples of decisions. The process is more involved. Steps:\n",
    "1. Collection of past examples of decision (training data)\n",
    "2. Clean the data, transform it into the format your algorithm likes (binary classes, vectors, numbers)\n",
    "3. Train then test your algorithm and fine-tune it\n",
    "4. Run predictions on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import machine learning algorithm\n",
    "from sklearn import tree\n",
    "\n",
    "# Steps 1 and 2. Training data (past decision examples)\n",
    "train_x = [[10, 34], [9, 4], [45, 20], [14, 20], [15, 20], [14, 19], [15, 19], [22, 17]]\n",
    "train_y = [ False,    True,    True,     False,    True,     False,    False,    False]\n",
    "\n",
    "# Step 3. Train ML algo (make your computer figure out the decision rules behind the training data)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "#Step 4\n",
    "print(clf.predict([[2, 2], [16, 17], [15, 20], [1, 32]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp; \n",
    "\n",
    "&nbsp; \n",
    "\n",
    "# Let's explore the process of machine learning through a fictional story!\n",
    "\n",
    "&nbsp; \n",
    "\n",
    "&nbsp; \n",
    "\n",
    "&nbsp; \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp; \n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c85876b-1b19-4c50-8330-a2c9dbd91f32",
    "_uuid": "3cae972238580fe9c4fb6a184b3661b232f77458"
   },
   "source": [
    "![title](pic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Arstotzka!\n",
    "### Things aren't going well and the country's food supplies are running short. If citizens want to eat, they have to send a letter to the Department of Food Supplies. The officials judge their requests and either reject them or send a slice of pizza.\n",
    "\n",
    "### You're the department's software engineer and your boss told you automate request approval with this new thing called machine learning... Your boss gave you the past decisions in the file, data.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_title</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>requester_received_pizza</th>\n",
       "      <th>requester_interests</th>\n",
       "      <th>account_age</th>\n",
       "      <th>requester_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_l25d7</td>\n",
       "      <td>Request Colorado Springs Help Us Please</td>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>792.420405</td>\n",
       "      <td>Nirsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_rcb83</td>\n",
       "      <td>[Request] California, No cash and I could use ...</td>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>False</td>\n",
       "      <td>['AskReddit', 'Eve', 'IAmA', 'MontereyBay', 'R...</td>\n",
       "      <td>1122.279838</td>\n",
       "      <td>Vescillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>t3_lpu5j</td>\n",
       "      <td>[Request] Hungry couple in Dundee, Scotland wo...</td>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>771.616181</td>\n",
       "      <td>Nirsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>t3_mxvj3</td>\n",
       "      <td>[Request] In Canada (Ontario), just got home f...</td>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>False</td>\n",
       "      <td>['AskReddit', 'DJs', 'IAmA', 'Random_Acts_Of_P...</td>\n",
       "      <td>741.035602</td>\n",
       "      <td>Vescillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>t3_1i6486</td>\n",
       "      <td>[Request] Old friend coming to visit. Would LO...</td>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>False</td>\n",
       "      <td>['BrosWeightLoss', 'RandomActsOfCookies', 'Ran...</td>\n",
       "      <td>308.633819</td>\n",
       "      <td>Nirsk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Unnamed: 0.1 request_id  \\\n",
       "0           0            0   t3_l25d7   \n",
       "1           1            1   t3_rcb83   \n",
       "2           2            2   t3_lpu5j   \n",
       "3           3            3   t3_mxvj3   \n",
       "4           4            4  t3_1i6486   \n",
       "\n",
       "                                       request_title  \\\n",
       "0            Request Colorado Springs Help Us Please   \n",
       "1  [Request] California, No cash and I could use ...   \n",
       "2  [Request] Hungry couple in Dundee, Scotland wo...   \n",
       "3  [Request] In Canada (Ontario), just got home f...   \n",
       "4  [Request] Old friend coming to visit. Would LO...   \n",
       "\n",
       "                             request_text_edit_aware requester_received_pizza  \\\n",
       "0  Hi I am in need of food for my 4 children we a...                    False   \n",
       "1  I spent the last money I had on gas today. Im ...                    False   \n",
       "2  My girlfriend decided it would be a good idea ...                    False   \n",
       "3  It's cold, I'n hungry, and to be completely ho...                    False   \n",
       "4  hey guys:\\n I love this sub. I think it's grea...                    False   \n",
       "\n",
       "                                 requester_interests  account_age  \\\n",
       "0                                                 []   792.420405   \n",
       "1  ['AskReddit', 'Eve', 'IAmA', 'MontereyBay', 'R...  1122.279838   \n",
       "2                                                 []   771.616181   \n",
       "3  ['AskReddit', 'DJs', 'IAmA', 'Random_Acts_Of_P...   741.035602   \n",
       "4  ['BrosWeightLoss', 'RandomActsOfCookies', 'Ran...   308.633819   \n",
       "\n",
       "  requester_city  \n",
       "0          Nirsk  \n",
       "1       Vescillo  \n",
       "2          Nirsk  \n",
       "3       Vescillo  \n",
       "4          Nirsk  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID:\t\t t3_1fhc8g \n",
      "\n",
      "Title:\t\t [Request] Broke student, been living off pasta for a good few weeks. A pizza may save my stomach's sanity! (UK) \n",
      "\n",
      "Text:\t\t As lovely as cheesy pasta is, it gets a bit boring after a while! I'm heading back to work over summer in a few weeks, so I can pay it forward when I get my first paycheck through :) \n",
      "\n",
      "Received:\t False \n",
      "\n",
      "Requester interests:\t ['AdviceAnimals', 'Antihumor', 'AskReddit', 'CornyJoke', 'FanTheories', 'FestivalSluts', 'GifSound', 'Heavymind', 'Hipsterchicks', 'IAmA', 'InternetIsBeautiful', 'LucidDreaming', 'Minecraft', 'Music', 'Paranormal', 'ProjectReddit', 'Psychonaut', 'RedditDayOf', 'RepublicOfMusic', 'Shaboozey', 'ShittyFanTheories', 'Slender_Man', 'Southampton', 'SquaredCircle', 'StonerEngineering', 'Straightdan', 'Survive', 'UniversityofReddit', 'WTF', 'WWE', 'WeAreTheMusicMakers', 'Yogscast', 'askdrugs', 'askscience', 'circlebroke', 'circlejerk', 'civ', 'coestar', 'conspiracy', 'counting', 'creepy', 'cringe', 'dayz', 'dayzlfg', 'ephemera', 'explainlikeimfive', 'facepalm', 'fffffffuuuuuuuuuuuu', 'fifthworldproblems', 'footballmanagergames', 'freewarewin', 'fucklebrothers', 'funny', 'futurebeats', 'gaming', 'geek', 'glitch_art', 'gonewild', 'heresapictureofme', 'ifyoulikeblank', 'keto', 'killingfloor', 'listentothis', 'meat', 'metacirclejerk', 'mildlyinteresting', 'mturk', 'newreddits', 'newzealand', 'nocontext', 'nosleep', 'notcirclejerk', 'offbeat', 'oxford', 'pics', 'queensnostalgia', 'radiohead', 'reactiongifs', 'redheads', 'rightinthechildhood', 'seduction', 'see', 'shamelessplug', 'shittyaskscience', 'skyrim', 'sleuths', 'technology', 'terriblefacebookmemes', 'thesims', 'tipofmypenis', 'tipofmytongue', 'todayilearned', 'unitedkingdom', 'whatwouldyoudoif', 'youhadtobethere'] \n",
      "\n",
      "Account age:\t 739.2040509259259 \n",
      "\n",
      "Requester city:\t Nirsk \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "i = 1017\n",
    "print('UID:\\t\\t', df['request_id'][i], '\\n')\n",
    "print('Title:\\t\\t', df['request_title'][i], '\\n')\n",
    "print('Text:\\t\\t', df['request_text_edit_aware'][i], '\\n')\n",
    "print('Received:\\t', df['requester_received_pizza'][i], '\\n')\n",
    "print('Requester interests:\\t', df['requester_interests'][i], '\\n')\n",
    "print('Account age:\\t', df['account_age'][i], '\\n')\n",
    "print('Requester city:\\t', df['requester_city'][i], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        3045\n",
       "True                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          994\n",
       "['2007scape', '3DS', 'AdviceAnimals', 'AnimalCrossing', 'AskReddit', 'Bowling', 'Eve', 'Foreversend', 'FryeMadden', 'FryeMadden2', 'HIMYM', 'IAmA', 'KarmaCourt', 'KarmaCourtAttorneys', 'KarmaCourtJury', 'KerbalSpaceProgram', 'Madden', 'Music', 'NBA2K13', 'PS4', 'Random_Acts_Of_Pizza', 'WTF', 'WhatsInThisThing', 'aviation', 'aww', 'cpp', 'fffffffuuuuuuuuuuuu', 'flightattendants', 'flying', 'funny', 'gamedev', 'gaming', 'gif', 'golf', 'halo', 'learnprogramming', 'loseit', 'mcservers', 'offmychest', 'pics', 'rebelmadden', 'roosterteeth', 'todayilearned', 'usu', 'videos', 'windowsphone', 'xboxone']       1\n",
       "Name: requester_received_pizza, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"requester_received_pizza\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3937\n",
      "True      104\n",
      "Name: request_text_edit_aware, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['request_text_edit_aware'].isna().value_counts())\n",
    "df = df.fillna(\"\")\n",
    "df = df[df[\"requester_received_pizza\"] != \"['2007scape', '3DS', 'AdviceAnimals', 'AnimalCrossing', 'AskReddit', 'Bowling', 'Eve', 'Foreversend', 'FryeMadden', 'FryeMadden2', 'HIMYM', 'IAmA', 'KarmaCourt', 'KarmaCourtAttorneys', 'KarmaCourtJury', 'KerbalSpaceProgram', 'Madden', 'Music', 'NBA2K13', 'PS4', 'Random_Acts_Of_Pizza', 'WTF', 'WhatsInThisThing', 'aviation', 'aww', 'cpp', 'fffffffuuuuuuuuuuuu', 'flightattendants', 'flying', 'funny', 'gamedev', 'gaming', 'gif', 'golf', 'halo', 'learnprogramming', 'loseit', 'mcservers', 'offmychest', 'pics', 'rebelmadden', 'roosterteeth', 'todayilearned', 'usu', 'videos', 'windowsphone', 'xboxone']\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24d5a591-79a6-4740-8b58-c76fef459355",
    "_uuid": "d231a3cdad2807893f44de861892093d02cb07a7"
   },
   "source": [
    "Summary of fields:\n",
    "\n",
    "**Input**:\n",
    " - `request_id`: unique identifier for the request \n",
    " - `request_title`: title of the reddit post for pizza request\n",
    " - `request_text_edit_aware`: expository to request for pizza\n",
    " - `requester_interests`: collected tags on what the interests of the requester are\n",
    " - `account_age`: how old is the account\n",
    " - `requester_city`: city requester is from\n",
    " \n",
    "**Output**:\n",
    " - `requester_recieved_pizza`: whether requester gets his/her pizza\n",
    " \n",
    " For our purpose let's choose the request text, interests and city as features to predict whether a person should receive a pizza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b869481f-c713-4aa6-aa0d-f2e5f4b2abfc",
    "_uuid": "a2cacb2270490a92ec9a7e920e8ca17c730c1e09"
   },
   "source": [
    "### Split training data before vectorization\n",
    "\n",
    "The first thing to do is to split our training data into 2 parts:\n",
    "\n",
    " - **training**: Use for training our model\n",
    " - **validation**: Use to check the \"soundness\" of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "0b61f317-079b-4253-b94a-a87b71bd47fb",
    "_uuid": "ac1e8766dcf5d7d81fe4fd3a95e7bc659fbf1978"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "train, valid = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8677912b-d9e2-4fd8-b722-acb3320af4fc",
    "_uuid": "f97576104bbabfc720fa0794ab6a8fc4e043f109"
   },
   "source": [
    "### Vectorize the train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "02efe9a8-00e4-41fa-9b6a-5fbebe751feb",
    "_uuid": "4549079bfedbbff679ccde5f083b3c6814e73233",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3232, 2205)\n",
      "(3232, 500)\n",
      "(3232, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "stopwords = [\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"    with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"]\n",
    "#\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\"\n",
    "    \n",
    "train_y = train['requester_received_pizza']\n",
    "valid_y = valid['requester_received_pizza']    \n",
    "\n",
    "count_vect_text = CountVectorizer(stop_words=stopwords, max_features=4000, min_df=6)\n",
    "train_x = coo_matrix(count_vect_text.fit_transform(train['request_text_edit_aware']))\n",
    "valid_x = coo_matrix(count_vect_text.transform(valid['request_text_edit_aware']))\n",
    "print(train_x.shape)\n",
    "\n",
    "count_vect_int = CountVectorizer(max_features=500, min_df=3)\n",
    "train_x_int = coo_matrix(count_vect_int.fit_transform(train['requester_interests']))\n",
    "valid_x_int = coo_matrix(count_vect_int.transform(valid['requester_interests']))\n",
    "print(train_x_int.shape)\n",
    "\n",
    "count_vect_city = CountVectorizer()\n",
    "train_x_city = coo_matrix(count_vect_city.fit_transform(train['requester_city']))\n",
    "valid_x_city = coo_matrix(count_vect_city.transform(valid['requester_city']))\n",
    "print(train_x_city.shape)\n",
    "\n",
    "train_x = hstack([train_x, train_x_int, train_x_city]).toarray()\n",
    "valid_x = hstack([valid_x, valid_x_int, valid_x_city]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d7ae411-ae2c-4098-beb2-ac6c2dc267a9",
    "_uuid": "3aaf138395ccdfe7a29d89d1b58da9db96ae8b36"
   },
   "source": [
    "# Step 3 - Training model\n",
    "\n",
    "### Let's try first a Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "8a159538-c58a-485d-bc23-d7115ee55a77",
    "_uuid": "44cee633360c7989a3d67716553ef4e2bc9eae87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB() \n",
    "clf.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c2776b5-6515-4321-a7e7-f925534241d6",
    "_uuid": "fbec702a6003287ea5d49049be532ee96b6d7a14"
   },
   "source": [
    "### Let's get a sense of how good our classifier is on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "a0bba339-cd62-46e9-9106-55ef15000dc5",
    "_uuid": "b5f7b1ac26a30b568d3f5dec2a3f76c34a316ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza giving accuracy:  0.7289603960396039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "predictions_valid = clf.predict(valid_x)\n",
    "print('Pizza giving accuracy: ', f1_score(predictions_valid, valid_y, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try another algorithm, Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza giving accuracy:  0.7735148514851485\n"
     ]
    }
   ],
   "source": [
    "#best params: alpha=0.01, loss='log', penalty='elasticnet', l1_ratio=0, tol=None, max_iter=30\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_SVM = SGDClassifier(alpha=0.01, loss='log', penalty='elasticnet', l1_ratio=0, tol=None, max_iter=30) \n",
    "clf_SVM.fit(train_x, train_y) \n",
    "predictions_valid = clf_SVM.predict(valid_x)\n",
    "print('Pizza giving accuracy: ', f1_score(predictions_valid, valid_y, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6013d400-4a01-438a-9afe-b540b6ec78b9",
    "_uuid": "dbf9eb2a3dde29a26ae51df05f120ee26334d0c3"
   },
   "source": [
    "# Step 4 - Run predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "2fe3ff2b-5157-43b2-ad8d-55389ad28a0e",
    "_uuid": "450827a713f7eaaa2d3c3504b038a513c27b3b20",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_data.csv')\n",
    "test = test.fillna(\"\")\n",
    "test_x = coo_matrix(count_vect_text.transform(test['request_text_edit_aware']))\n",
    "test_x_int = coo_matrix(count_vect_int.transform(test['requester_interests']))\n",
    "test_x_city = coo_matrix(count_vect_city.transform(test['requester_city']))\n",
    "test_x = hstack([test_x, test_x_int, test_x_city]).toarray()\n",
    "\n",
    "predictions = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ef6b8e68-46be-4944-b809-872ddeabf386",
    "_uuid": "51a804beaf030dbb8cbdfc320d6a26d86991d274"
   },
   "source": [
    "**Note:** Since we don't have the `requester_received_pizza` field in test data, we can't measure accuracy. But we can do some exploration as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "80300555-265f-4557-8b52-17c343a34c58",
    "_uuid": "4ad28c27f351de96d40b68aed92217b17f71c542"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1302\n",
       "True      329\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Assume something is wrong and find it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nirsk       261\n",
      "Vescillo     68\n",
      "Name: requester_city, dtype: int64\n",
      "Nirsk       843\n",
      "Vescillo    788\n",
      "Name: requester_city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.concat([test, pd.Series(predictions)], axis=1)\n",
    "received_pizza = pred_df[pred_df[0] == 'True']\n",
    "print(received_pizza['requester_city'].value_counts())\n",
    "print(pred_df['requester_city'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
